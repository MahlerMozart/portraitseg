from collections import OrderedDict

from torch.optim import SGD, RMSprop
from torch.nn.functional import cross_entropy

from portraitseg.utils import (cross_entropy2d)

"""Using a dictionary like this is a form of hand-tuning, a slow approach.
Consider using an automatic search method like random search, where your job is
to specify ranges and scales rather than specific hyperparameter values.
"""

# TODO: Prepend this dictionary to the Postgres configurations table
configurations = {
    1: OrderedDict(
        data_aug=None,
        lr=1e-10,
        momentum=0,
        weight_decay=0,
        lr_bias=2e-14,          # ## oops
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=100000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    2: OrderedDict(
        data_aug=None,
        lr=1e-10,
        momentum=0.99,
        weight_decay=0.0005,
        lr_bias=2e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=100000,
        loss_fn_kwargs={"size_average": False},
        update_interval=1,  # 10 in authors' code
        shuffle_every_epoch=True),
    3: OrderedDict(
        data_aug=None,
        lr=1e-14,
        momentum=0.99,
        weight_decay=0.0005,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=100000,
        loss_fn_kwargs={"size_average": False},
        update_interval=1,
        shuffle_every_epoch=True),
    4: OrderedDict(
        data_aug=None,
        lr=1e-14,
        momentum=0.99,
        weight_decay=0.0005,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,  # Replace with CrossEntropyLoss2d
        max_iter=100000,
        loss_fn_kwargs={"size_average": False},
        update_interval=1,
        shuffle_every_epoch=True),
    5: OrderedDict(
        data_aug=None,
        lr=1e-4,  # Divide color channels by 255   # NaN
        momentum=0.99,
        weight_decay=0.0005,
        lr_bias=2e-4,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        update_interval=10,
        shuffle_every_epoch=True),
    6: OrderedDict(
        data_aug=1,  # first data aug, see notes
        lr=1e-4,
        momentum=0.99,
        weight_decay=0.0005,
        lr_bias=2e-4,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        update_interval=10,
        shuffle_every_epoch=True),
    7: OrderedDict(
        data_aug=None,
        lr=1e-4,  # Divide color channels by 255   # NaN
        momentum=0.99,
        weight_decay=0.0005,
        lr_bias=2e-4,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        update_interval=10,
        shuffle_every_epoch=True),
    8: OrderedDict(
        data_aug=None,
        lr=1e-10,
        momentum=0,
        weight_decay=0,
        lr_bias=2e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=10,
        shuffle_every_epoch=True),
    9: OrderedDict(
        data_aug=None,
        dropout=0,  # ############
        lr=1e-10,
        momentum=0,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=100000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    10: OrderedDict(
         data_aug=None,
         dropout=0,
         lr=1e-10,
         momentum=0,
         weight_decay=0,
         lr_bias=2e-10,  # ############
         weight_decay_bias=0,
         optimizer=SGD,
         loss_fn=cross_entropy2d,
         max_iter=100000,
         loss_fn_kwargs={"size_average": False},
         optimizer_kwards={},
         update_interval=1,
         shuffle_every_epoch=True),
    11: OrderedDict(
         data_aug=None,
         dropout=0.5,
         lr=1e-10,
         momentum=0,
         weight_decay=0,
         lr_bias=2e-10,
         weight_decay_bias=0,
         optimizer=RMSprop,  # ############
         loss_fn=cross_entropy2d,
         max_iter=100000,
         loss_fn_kwargs={"size_average": False},
         optimizer_kwards={},
         update_interval=1,
         shuffle_every_epoch=True),
    # http://pytorch.org/docs/master/optim.html#torch.optim.RMSprop
    12: OrderedDict(
         data_aug=None,
         dropout=0.5,
         lr=1e-2,
         momentum=0,
         weight_decay=0,
         lr_bias=2e-2,
         weight_decay_bias=0,
         optimizer=RMSprop,  # ############
         loss_fn=cross_entropy2d,
         max_iter=100000,
         loss_fn_kwargs={"size_average": False},
         optimizer_kwards={},
         update_interval=1,
         shuffle_every_epoch=True),
    13: OrderedDict(
         data_aug=None,
         dropout=0,
         lr=1e-4,  # ############
         momentum=0,
         weight_decay=0,
         lr_bias=2e-10,
         weight_decay_bias=0,
         optimizer=RMSprop,
         loss_fn=cross_entropy2d,
         max_iter=100000,
         loss_fn_kwargs={"size_average": False},
         optimizer_kwards={},
         update_interval=1,
         shuffle_every_epoch=True),
    14: OrderedDict(
         data_aug=None,
         dropout=0,
         lr=1e-4,
         momentum=0,
         weight_decay=0,
         lr_bias=1e-4,                # ############
         weight_decay_bias=0,
         optimizer=RMSprop,
         loss_fn=cross_entropy2d,
         max_iter=200000,  # ############
         loss_fn_kwargs={"size_average": False},
         optimizer_kwards={},
         update_interval=1,
         shuffle_every_epoch=True),
    15: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-4,            # ############
        momentum=0,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    16: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-7,            # ############
        momentum=0,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    17: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-9,            # ############
        momentum=0,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    18: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    19: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0.1,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    20: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0.2,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    21: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0.2,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    22: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0.4,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    23: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0.5,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    24: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,            # ############
        momentum=0.6,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    25: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-8,
        momentum=0.7,
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    26: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-10,             # ############
        momentum=0.1,    # ############
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    27: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-10,
        momentum=0.9,    # ############
        weight_decay=0,
        lr_bias=2e-14,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    28: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-10,
        momentum=0.2,  # ############
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    29: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-10,
        momentum=0.5,  # ############
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    30: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-10,
        momentum=0.4,  # ############
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    31: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-11,  # ############
        momentum=0.5,  # ############
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    32: OrderedDict(
        data_aug=None,
        dropout=0,
        lr=1e-7,  # ############
        momentum=0.5,  # ############
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True,
        divide_by_255=True),
    33: OrderedDict(  # config 29 with mirroring
        data_aug=1,  # mirroring
        dropout=0,
        lr=1e-10,
        momentum=0.5,
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    34: OrderedDict(  # config 29 with random crop
        data_aug=2,  # random crop
        dropout=0,
        lr=1e-10,
        momentum=0.5,
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    35: OrderedDict(  # config 29 with random crop and mirroring
        data_aug=3,  # random crop and mirroring
        dropout=0,
        lr=1e-10,
        momentum=0.5,
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=500000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    36: OrderedDict(  # config 35 with dropout
        data_aug=3,
        dropout=0.5,
        lr=1e-10,
        momentum=0.5,
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=500000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    37: OrderedDict(  # config 29 with dropout
        data_aug=None,
        dropout=0.5,
        lr=1e-10,
        momentum=0.5,  # ############
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy2d,
        max_iter=500000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    38: OrderedDict(  # config 35 with loss averaging, and a new CE function
        data_aug=3,  # random crop and mirroring
        dropout=0,
        lr=1e-10,
        momentum=0.5,
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy,  # Trying a new cross_entropy function
        max_iter=500000,
        loss_fn_kwargs=None,  # Enable averaging (remove the disable setting)
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True),
    39: OrderedDict(  # config 33 with PyTorch's cross-entropy
        data_aug=1,  # mirroring
        dropout=0,
        lr=1e-10,
        momentum=0.5,
        weight_decay=0,
        lr_bias=1e-10,
        weight_decay_bias=0,
        optimizer=SGD,
        loss_fn=cross_entropy,
        max_iter=200000,
        loss_fn_kwargs={"size_average": False},
        optimizer_kwards={},
        update_interval=1,
        shuffle_every_epoch=True,
        divide_by_255=False),
}


def get_config(config_id):
    config = configurations[config_id]
    if 'dropout' not in config.keys():
        config['dropout'] = 0.5
    return config
