{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.chdir(\"../../\")  # If ran from test directory.\n",
    "\n",
    "import mkl\n",
    "nproc = mkl.get_max_threads()  # e.g. 12\n",
    "mkl.set_num_threads(nproc)\n",
    "\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from portraitseg.pytorch_dataloaders import get_train_valid_loader\n",
    "from portraitseg.utils import (plots,\n",
    "                               set_seed,\n",
    "                               show_portrait_pred_mask,\n",
    "                               scoretensor2mask)\n",
    "from portraitseg.portraitfcn import PortraitFCN\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    n, c, h, w = input.size()\n",
    "    log_p = F.log_softmax(input)\n",
    "    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
    "    log_p = log_p[target.view(n * h * w, 1).repeat(1, c) >= 0].cuda()\n",
    "    log_p = log_p.view(-1, c)\n",
    "    mask = target >= 0\n",
    "    target = target[mask]\n",
    "    loss = F.nll_loss(log_p, target, weight=weight, size_average=False)\n",
    "    if size_average:\n",
    "        loss /= mask.data.sum()\n",
    "    return loss\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "SEED = 3\n",
    "set_seed(SEED)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "FLICKR_DIR = DATA_DIR + \"portraits/flickr/\"\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Load pretrained FCN8s\n",
    "model = PortraitFCN().cuda()\n",
    "path_to_weights = \"portraitseg/portraitfcn_untrained.pth\"\n",
    "model.load_state_dict(torch.load(path_to_weights))\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 1\n",
    "AUGMENT = False\n",
    "LR = 1e-10\n",
    "NB_EPOCHS = 200\n",
    "VALID_SIZE = 0.2\n",
    "loss_fn = cross_entropy2d\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "# Get DataLoaders\n",
    "trn_loader, val_loader = get_train_valid_loader(FLICKR_DIR,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                augment=AUGMENT,\n",
    "                                                random_seed=SEED,\n",
    "                                                valid_size=VALID_SIZE,\n",
    "                                                show_sample=False,\n",
    "                                                num_workers=6,\n",
    "                                                pin_memory=True)\n",
    "\n",
    "portraits, masks = next(iter(trn_loader))\n",
    "portraits, masks = Variable(portraits).cuda(), Variable(masks).cuda()\n",
    "\n",
    "portrait = portraits[0].data.clone().cpu()\n",
    "mask = masks[0].data.clone().cpu()\n",
    "\n",
    "# Train\n",
    "    # Roughly 42 seconds per 100 epochs on one sample\n",
    "    # Idea: \"Is the network powerful enough to at least memorize?\"\n",
    "preds = []\n",
    "start = time()\n",
    "for epoch in range(NB_EPOCHS):\n",
    "    model.train()\n",
    "    outputs = model(portraits)\n",
    "    loss = loss_fn(outputs, masks, size_average=False)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 99:\n",
    "        # Test on validation set\n",
    "        model.eval()\n",
    "        outputs = model(portraits)\n",
    "        loss = loss_fn(outputs, masks, size_average=False)\n",
    "        print(\"Validation loss: %.3f\" % (loss.data[0]))\n",
    "        print(\"Duration (1 sample, 100 epochs): %.2f seconds\" % (time() - start))\n",
    "        scoretensor = outputs[0].data.cpu()\n",
    "        pred = scoretensor2mask(scoretensor)\n",
    "        preds.append(pred)\n",
    "        show_portrait_pred_mask(portrait, preds, mask)\n",
    "        start = time()\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
